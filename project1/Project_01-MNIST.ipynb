{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f918dc02-25b4-47af-8364-2389498553d6",
   "metadata": {},
   "source": [
    "# Project 01 - MNIST\n",
    "\n",
    "Hello and Welcome to our first project this Semster: MNIST. Not very exciting, but we will look at some basic concepts and try to generate some nice handwritten digits.\n",
    "\n",
    "__Deadline__: 30.11.2023 @ 14:30\n",
    "\n",
    "__Submission__: Please upload your finished notebooks here: https://fz-juelich.sciebo.de/s/TSh1kiGtjz9y27l. The name of the notebook should contain the HHU-ID of every member in your group.\n",
    "\n",
    "\n",
    "## Project\n",
    "\n",
    "In your last lecture you learned about Kernel Densitiy Estimations, a method used to estimate the true distribution of some dataset, by super imposing some gaussian kernels. When sampling from this KDE we generate nice looking images, but the image space is mostly empty and we can't really generate new looking digits. We want to quantify these two attributes (nice looking image and new looking digits) in this notebook to evalute our approach.\n",
    "\n",
    "## Data\n",
    "We will use the higher resolution (28x28) MNIST dataset: https://www.openml.org/search?type=data&status=any&id=554. You can download it into your notebook by using https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html.\n",
    "\n",
    "## Metrics\n",
    "First we define the metrics, that we want to use. We will steal some ideas from the Inception and the FID Score, which you will encounter later into the lecture.\n",
    "We established that we would like our new images to a) look convincing and b) look new and not to be copies of our training data.\n",
    "To quantify these two goals we will define two metrics.\n",
    "* The first metric \"Quality\" will use a classifier. If the classifier is certain about the class of our generated digit (one single high probability), we assume it to be convincing.\n",
    "* The second metric \"Novelty\" will use the latent space of this classifier. It will check the minimal distance between a generated digit and all training data in the latent space, the higher this distance the better.\n",
    "\n",
    "The concrete implementation of these metrics is up to you. U can use the provided model as your basis for the classifier. The input to your metrics should be a list or an array of images, the output a value between 0 and 1, averaged for all images.\n",
    "\n",
    "## Models\n",
    "Second you will compare a simple KDE approach with a slightly more sophisticated autoencoder approach.\n",
    "\n",
    "Our first model will be a KDE in the PCA space of our training data. We will calculate a PCA and then \"train\" a KDE in this space. Generate 10,000 random images and calculate our metrics for them. Do our metrics support our previous claims regarding the KDE? Look at the influence of the bandwidth parameter on the two metrics.\n",
    "\n",
    "Next we will train an autoencoder, you can use the provided model as a basis for your training. Calculate the latent space representation for our data and calculate a second KDE in the latent space. Also generate 10,000 random images and calculate our metrics. Did the autoencoder improve our results? Also check different values for the bandwidth.\n",
    "\n",
    "## Interpolation\n",
    "We know we can't interpolate in the image space to get from one digit to another (for example transform a 0 into a 1). But does it work in the latent space of our autoencoder? Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88169a68-b2eb-4903-94dd-6648217d8ed6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sutto\\Dropbox\\!Masters Work\\gm\\project1\\Project_01-MNIST.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sutto/Dropbox/%21Masters%20Work/gm/project1/Project_01-MNIST.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sutto/Dropbox/%21Masters%20Work/gm/project1/Project_01-MNIST.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sutto/Dropbox/%21Masters%20Work/gm/project1/Project_01-MNIST.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m cdist\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sutto/Dropbox/%21Masters%20Work/gm/project1/Project_01-MNIST.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# sklearn imports\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# torch imports\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# custom imports\n",
    "from models import Autoencoder, Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748df96-d1d3-4d37-9b82-5d54bda84841",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "1. Train a classifier for the MNIST dataset\n",
    "2. Define the Quality metric\n",
    "    * Higher, when the classfier is certain (High Softmax)\n",
    "    * Averaged for all images\n",
    "    * Between 0 and 1\n",
    "4. Define the Novelty metric\n",
    "    * Higher, when an image has a high distance in the latent space from all training data points\n",
    "    * Averaged for all images\n",
    "    * Between 0 and 1\n",
    "5. Check your metrics with the original dataset. What Novelty score do you expect? Also calculate the Novelty score for one half of the data versus the other half?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a40295-d2f7-4802-aafd-6a9076546d7a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e381b-e9cb-4627-81b6-f95db9052fc9",
   "metadata": {},
   "source": [
    "### Simple KDE\n",
    "\n",
    "1. Calculate a PCA for the data\n",
    "2. Calculate a KDE for the transformed data points\n",
    "3. Sample 10,000 new images from the KDE (don't forget pca.inverse_transform)\n",
    "4. Calulcate Quality and Novelty metrics\n",
    "5. Repeat 2 to 4 for different bandwidths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7f2c7-37c2-4dd4-bf2e-1f54f2ec4423",
   "metadata": {},
   "source": [
    "### Autoencoder + KDE\n",
    "\n",
    "1. Train an autoencoder to reconstruct the MNIST data\n",
    "2. Apply the encoder to all images to get all latent space representations\n",
    "3. Get the KDE for these latent space representations\n",
    "4. Sample 10,000 new latent space representations\n",
    "5. Use the decoder (+head) of our autoencoder to reconstruct images from these latent space representations\n",
    "6. Calculate the Quality and Novelty metrics\n",
    "7. Repeat steps 3 to 6 for different bandwidths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f26ed3-2aa3-483a-9cbb-732781489498",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "\n",
    "1. Choose a pair of MNIST images\n",
    "2. Apply the encoder of your autoencoder\n",
    "3. Interpolate between these two latent space represenations\n",
    "4. Reconstruct the images for these interpolated latent space representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993026d4-db8a-401f-ac7e-71b0c548087f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feedback\n",
    "* __Length__: (Too short or too long)\n",
    "* __Difficulty__: (Too easy or too hard)\n",
    "* __Guidance__: (Too much guidance or too little)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
